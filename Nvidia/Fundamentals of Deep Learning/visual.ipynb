{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Next Steps Project\n",
    "This notebook provides a more advanced and less structured exercise for students who have completed the NVIDIA DLI workshop *[Fundamentals of Deep Learning](https://www.nvidia.com/content/dam/en-zz/Solutions/deep-learning/deep-learning-education/dli-fundamentals-of-deep-learning-1369828-r3-web.pdf)* and wish to practice more before working on their own applications.\n",
    "\n",
    "The container this Jupyter Lab environment is running in was also used in the workshop, so, you can use all the same libraries and techniques from the workshop while working on this exercise."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Project: Visualize a Neural Network\n",
    "In the Lecture 3, this is a slide that visualizes a neural network:\n",
    "\n",
    "![lecture_3_network](03_ASL/images/kernels_and_neural_networks.png)\n",
    "\n",
    "To make this slide, we used the same neural network that was built in notebook 03_asl_cnn.ipynb, and extracted the weights from the layers. We would like to encourage you to do the same thing. Not only is this a great debugging tool with Keras, but it can also make some pretty cool images!\n",
    "**The open-ended goal of this *Next Steps* project is to learn how to visualize Keras layers.**"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load the Data\n",
    "To get started, Keras has mnist built right in it. Use the command below to load it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()\n",
    "\n",
    "# Normalize our image data\n",
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_valid = x_valid.reshape(-1,28,28,1)\n",
    "\n",
    "num_categories = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build a Model\n",
    "Next, we'll build a simple model to help get started. Try modifying the model into increasingly complex models to see how this changes the images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 15s 6ms/step - loss: 0.4775 - accuracy: 0.8597 - val_loss: 0.2805 - val_accuracy: 0.9182\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2895 - accuracy: 0.9173 - val_loss: 0.2560 - val_accuracy: 0.9236\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2653 - accuracy: 0.9250 - val_loss: 0.2552 - val_accuracy: 0.9265\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2516 - accuracy: 0.9284 - val_loss: 0.2499 - val_accuracy: 0.9272\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2415 - accuracy: 0.9323 - val_loss: 0.2273 - val_accuracy: 0.9342\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x11856edae20>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(1, (3, 3), padding=\"same\", activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation=\"relu\"))\n",
    "model.add(Dense(units=num_categories, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get the Weights\n",
    "\n",
    "After a model trains, we can get the weights of a layer with the [get_weights](https://keras.io/api/layers/base_layer/#get_weights-method) method. Below shows a sample of how to plot the kernel trained in the Conv2D layer above. Can you figure out how to see the Dense layer? Or can you add another Conv2D layer and plot all the kernels?\n",
    "\n",
    "There are many types of model architectures. Play around and see if you can find a relationship between what the model learns and the data that is fed into it. Good luck and have fun!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x11800ad02b0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Grab weights from 0th layer.\n",
    "layer_weights = model.get_weights()[0]\n",
    "# layer weights are represented by 4 dimensions. Can you figure out what each dimension represents?\n",
    "\n",
    "kernel_weights = layer_weights[:,:,0,:]\n",
    "# Uncomment to see raw\n",
    "#print(layer_weights)\n",
    "#print(kernel_weights)\n",
    "plt.imshow(kernel_weights,cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Additional Resources\n",
    "\n",
    "Can't wait to learn more? Check out these additional resources:\n",
    "\n",
    "* [Practical Deep Learning for Cloud, Mobile, and Edge](https://www.oreilly.com/library/view/practical-deep-learning/9781492034858/) - O'Reilly Book\n",
    "* [A Survey of Knowledge-Enhanced Text Generation](https://paperswithcode.com/paper/a-survey-of-knowledge-enhanced-text) - An exploration of how to include more context in text generation\n",
    "* [Illustrated: 10 CNN Architectures](https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d) - A visual look into popular CNN Architectures\n",
    "* [Convolutional Neural Network (CNN)](https://developer.nvidia.com/discover/convolutional-neural-network) - An overview of CNNs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}