{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train,y_train),(x_valid,y_valid) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 28, 28)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "60000 Samples of Images 28x28 = 784 Length array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x1de7d3aab00>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[0]\n",
    "plt.imshow(image, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Flattening the Image Data\n",
    "We are going to simplify thing and reshape data from 2D image into single 1D array"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 784)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000,784)\n",
    "x_valid = x_valid.reshape(10000,784)\n",
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,  18,  18,\n       126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n       253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253,\n       253, 253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 219, 253,\n       253, 253, 253, 253, 198, 182, 247, 241,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n        80, 156, 107, 253, 253, 205,  11,   0,  43, 154,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,  14,   1, 154, 253,  90,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0, 139, 253, 190,   2,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,  70,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n       241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,  81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,  45, 186, 253, 253, 150,  27,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,  16,  93, 252, 253, 187,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249,\n       253, 249,  64,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  46, 130,\n       183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n       229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114,\n       221, 253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  23,  66,\n       213, 253, 253, 253, 253, 198,  81,   2,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  18, 171,\n       219, 253, 253, 253, 253, 195,  80,   9,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55, 172,\n       226, 253, 253, 253, 253, 244, 133,  11,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n       136, 253, 253, 253, 212, 135, 132,  16,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         0,   0,   0,   0], dtype=uint8)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalizing the Image Data\n",
    "Deep learning models are better at dealing with floating point numbers between 0 and 1\n",
    "So we are going to divide values by 255(max value)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(dtype('float64'), 1.0, 0.0)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype,x_train.max(), x_train.min()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorically Encoding the Labels\n",
    "y_values are in range of 10, so we create a label with first 10 values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:9]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model  = Sequential()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the input layer\n",
    "The `units` argument specifies the number of neurons in the layer. We are going to use `512` which we have chosen from experimentation. Choosing the correct number of neurons is what puts the \"science\" in \"data science\" as it is a matter of capturing the statistical complexity of the dataset. Try playing around with this value later to see how it affects training and to start developing a sense for what this number means.\n",
    "\n",
    "We will learn more about activation functions later, but for now, we will use the `relu` activation function, which in short, will help our network to learn how to make more sophisticated guesses about data than if it were required to make guesses based on some strictly linear function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units = 512, activation = 'relu',input_shape=(784,)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the hidden layer\n",
    "Now we will add densely connected layer. Again, much more will be said about these later, but for now know that these layers give the network more parameters to contribute towards its guesses, and therefore, more subtle opportunities for accurate learning:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation = 'relu'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the output layer\n",
    "The output layer is the layer that will be used to make the final predictions. In this case, we will use the `softmax` activation function, which will make the output values between 0 and 1, and will make it easier to interpret the output as a probability distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compiling the Model\n",
    "Again, more details are to follow, but the final step we need to do before we can actually train our model with data is to [compile](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#compile) it. Here we specify a [loss function](https://developers.google.com/machine-learning/glossary#loss) which will be used for the model to understand how well it is performing during training. We also specify that we would like to track `accuracy` while the model trains:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%model.summary()\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1860 - accuracy: 0.9431 - val_loss: 0.1402 - val_accuracy: 0.9575\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0806 - accuracy: 0.9743 - val_loss: 0.0887 - val_accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0569 - accuracy: 0.9818 - val_loss: 0.0780 - val_accuracy: 0.9776\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0438 - accuracy: 0.9858 - val_loss: 0.0938 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0336 - accuracy: 0.9891 - val_loss: 0.0688 - val_accuracy: 0.9802\n"
     ]
    }
   ],
   "source": [
    "#model.fit(x_train, y_train, epochs = 10, batch_size = 32)\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%dasd\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.06884608417749405\n",
      "Test accuracy: 0.9801999926567078\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_valid, y_valid, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%dasd\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ☆ Bonus Exercise ☆\n",
    "\n",
    "Have time to spare? In the next section, we will talk about how we arrived at some of the numbers above, but we can try imagining what it was like to be a researcher developing the techniques commonly used today.\n",
    "\n",
    "Ultimately, each neuron is trying to fit a line to some data. Below, we have some datapoints and a randomly drawn line using the equation [y = mx + b](https://www.mathsisfun.com/equation_of_line.html).\n",
    "\n",
    "Try changing the `m` and the `b` in order to find the lowest possible loss. How did you find the best line? Can you make a program to follow your strategy?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 14.905000000000006\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "m = 5.1\n",
    "b = 14.4\n",
    "\n",
    "# Sample data\n",
    "\n",
    "x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
    "y_hat = x * m + b\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, y_hat, '-')\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\", np.sum((y - y_hat)**2)/len(x))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}