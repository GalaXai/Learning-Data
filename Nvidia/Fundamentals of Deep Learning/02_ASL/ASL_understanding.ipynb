{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Image Classification of an American Sign Language Dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading the Data\n",
    "Dataset is in CSV format. To load and work with the data, we'll be using Pandas library."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_df = pd.read_csv(\"data/asl_data/sign_mnist_train.csv\")\n",
    "validation_df = pd.read_csv(\"data/asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploring the data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n0      3     107     118     127     134     139     143     146     150   \n1      6     155     157     156     156     156     157     156     158   \n2      2     187     188     188     187     187     186     187     188   \n3      2     211     211     212     212     211     210     211     210   \n4     12     164     167     170     172     176     179     180     184   \n\n   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n0     153  ...       207       207       207       207       206       206   \n1     158  ...        69       149       128        87        94       163   \n2     187  ...       202       201       200       199       198       199   \n3     210  ...       235       234       233       231       230       226   \n4     185  ...        92       105       105       108       133       163   \n\n   pixel781  pixel782  pixel783  pixel784  \n0       206       204       203       202  \n1       175       103       135       149  \n2       198       195       194       195  \n3       225       222       229       163  \n4       157       163       164       179  \n\n[5 rows x 785 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>107</td>\n      <td>118</td>\n      <td>127</td>\n      <td>134</td>\n      <td>139</td>\n      <td>143</td>\n      <td>146</td>\n      <td>150</td>\n      <td>153</td>\n      <td>...</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>207</td>\n      <td>206</td>\n      <td>206</td>\n      <td>206</td>\n      <td>204</td>\n      <td>203</td>\n      <td>202</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>155</td>\n      <td>157</td>\n      <td>156</td>\n      <td>156</td>\n      <td>156</td>\n      <td>157</td>\n      <td>156</td>\n      <td>158</td>\n      <td>158</td>\n      <td>...</td>\n      <td>69</td>\n      <td>149</td>\n      <td>128</td>\n      <td>87</td>\n      <td>94</td>\n      <td>163</td>\n      <td>175</td>\n      <td>103</td>\n      <td>135</td>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>187</td>\n      <td>188</td>\n      <td>188</td>\n      <td>187</td>\n      <td>187</td>\n      <td>186</td>\n      <td>187</td>\n      <td>188</td>\n      <td>187</td>\n      <td>...</td>\n      <td>202</td>\n      <td>201</td>\n      <td>200</td>\n      <td>199</td>\n      <td>198</td>\n      <td>199</td>\n      <td>198</td>\n      <td>195</td>\n      <td>194</td>\n      <td>195</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>211</td>\n      <td>211</td>\n      <td>212</td>\n      <td>212</td>\n      <td>211</td>\n      <td>210</td>\n      <td>211</td>\n      <td>210</td>\n      <td>210</td>\n      <td>...</td>\n      <td>235</td>\n      <td>234</td>\n      <td>233</td>\n      <td>231</td>\n      <td>230</td>\n      <td>226</td>\n      <td>225</td>\n      <td>222</td>\n      <td>229</td>\n      <td>163</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>164</td>\n      <td>167</td>\n      <td>170</td>\n      <td>172</td>\n      <td>176</td>\n      <td>179</td>\n      <td>180</td>\n      <td>184</td>\n      <td>185</td>\n      <td>...</td>\n      <td>92</td>\n      <td>105</td>\n      <td>105</td>\n      <td>108</td>\n      <td>133</td>\n      <td>163</td>\n      <td>157</td>\n      <td>163</td>\n      <td>164</td>\n      <td>179</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "y_train = training_df['label']\n",
    "y_valid = validation_df['label']\n",
    "\n",
    "del training_df['label']\n",
    "del validation_df['label']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extracting the Images"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "x_train = training_df.values\n",
    "x_valid = validation_df.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summarizing the Training and Validation Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "((27455, 784), (27455,), (7172, 784), (7172,))"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape , x_valid.shape, y_valid.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "array([107, 118, 127, 134, 139, 143, 146, 150, 153, 156, 158, 160, 163,\n       165, 159, 166, 168, 170, 170, 171, 171, 171, 172, 171, 171, 170,\n       170, 169, 111, 121, 129, 135, 141, 144, 148, 151, 154, 157, 160,\n       163, 164, 170, 119, 152, 171, 171, 170, 171, 172, 172, 172, 172,\n       172, 171, 171, 170, 113, 123, 131, 137, 142, 145, 150, 152, 155,\n       158, 161, 163, 164, 172, 105, 142, 170, 171, 171, 171, 172, 172,\n       173, 173, 172, 171, 171, 171, 116, 125, 133, 139, 143, 146, 151,\n       153, 156, 159, 162, 163, 167, 167,  95, 144, 171, 172, 172, 172,\n       172, 172, 173, 173, 173, 172, 172, 171, 117, 126, 134, 140, 145,\n       149, 153, 156, 158, 161, 163, 164, 175, 156,  87, 154, 172, 173,\n       173, 173, 173, 173, 174, 174, 174, 173, 172, 172, 119, 128, 136,\n       142, 146, 150, 153, 156, 159, 163, 165, 164, 184, 148,  89, 164,\n       172, 174, 174, 174, 174, 175, 175, 174, 175, 174, 173, 173, 122,\n       130, 138, 143, 147, 150, 154, 158, 162, 165, 166, 172, 181, 128,\n        94, 170, 173, 175, 174, 175, 176, 177, 177, 177, 177, 175, 175,\n       174, 122, 132, 139, 145, 149, 152, 156, 160, 163, 165, 166, 181,\n       172, 103, 113, 175, 176, 178, 178, 179, 179, 179, 179, 178, 179,\n       177, 175, 174, 125, 134, 141, 147, 150, 153, 157, 161, 164, 167,\n       168, 184, 179, 116, 126, 165, 176, 179, 180, 180, 181, 180, 180,\n       180, 179, 178, 177, 176, 128, 135, 142, 148, 152, 154, 158, 162,\n       165, 168, 170, 187, 180, 156, 161, 124, 143, 179, 178, 178, 181,\n       182, 181, 180, 181, 180, 179, 179, 129, 136, 144, 150, 153, 155,\n       159, 163, 166, 169, 172, 187, 184, 153, 102, 117, 110, 175, 169,\n       154, 182, 183, 183, 182, 182, 181, 181, 179, 131, 138, 145, 150,\n       155, 157, 161, 165, 168, 174, 190, 189, 175, 146,  94,  97, 113,\n       151, 158, 129, 184, 184, 184, 184, 183, 183, 182, 180, 131, 139,\n       146, 151, 155, 159, 163, 167, 175, 182, 179, 171, 159, 114, 102,\n        89, 121, 136, 136,  96, 172, 186, 186, 185, 185, 184, 182, 181,\n       131, 140, 147, 154, 157, 160, 164, 179, 186, 191, 187, 180, 157,\n       100,  88,  84, 108, 111, 126,  90, 120, 186, 187, 187, 186, 185,\n       184, 182, 133, 141, 149, 155, 158, 160, 174, 201, 189, 165, 151,\n       143, 146, 120,  87,  78,  87,  76, 108,  98,  96, 181, 188, 187,\n       186, 186, 185, 183, 133, 141, 150, 156, 160, 161, 179, 197, 174,\n       135,  99,  72,  95, 134,  97,  72,  74,  68, 116, 105, 108, 187,\n       189, 187, 187, 186, 186, 185, 134, 143, 151, 156, 161, 163, 179,\n       194, 156, 110,  74,  42,  52, 139,  94,  67,  75,  75, 118, 106,\n       129, 189, 191, 190, 188, 188, 187, 186, 135, 144, 152, 158, 163,\n       163, 177, 193, 161, 122,  84,  43,  71, 134,  81,  57,  71,  88,\n       112,  98, 157, 193, 193, 192, 190, 190, 189, 188, 136, 144, 152,\n       158, 162, 163, 176, 192, 164, 128,  98,  62,  60, 100,  71,  76,\n        96, 101, 105,  95, 174, 195, 194, 194, 194, 193, 191, 190, 137,\n       145, 152, 159, 164, 165, 178, 191, 164, 135, 113,  82,  59,  87,\n        98, 111, 120, 108,  97, 108, 190, 196, 195, 195, 194, 193, 193,\n       192, 139, 146, 154, 160, 164, 165, 175, 186, 163, 139, 112,  85,\n        67, 102, 126, 133, 126, 105, 104, 176, 197, 198, 197, 196, 195,\n       195, 194, 193, 138, 147, 155, 161, 165, 167, 172, 186, 163, 137,\n       107,  87,  76, 106, 122, 125, 117,  96, 156, 199, 199, 200, 198,\n       196, 196, 195, 195, 194, 139, 148, 156, 163, 166, 168, 172, 180,\n       158, 131, 108,  99,  86, 108, 118, 116, 103, 107, 191, 202, 201,\n       200, 200, 200, 199, 197, 198, 196, 140, 149, 157, 164, 168, 167,\n       177, 178, 155, 131, 118, 105,  87, 100, 106, 100,  96, 164, 202,\n       202, 202, 202, 202, 201, 200, 199, 199, 198, 140, 150, 157, 165,\n       167, 170, 181, 175, 152, 130, 115,  98,  82,  85,  90,  99, 165,\n       202, 203, 204, 203, 203, 202, 202, 201, 201, 200, 200, 142, 150,\n       159, 165, 170, 191, 173, 157, 144, 119,  97,  84,  79,  79,  91,\n       172, 202, 203, 203, 205, 204, 204, 204, 203, 202, 202, 201, 200,\n       142, 151, 160, 165, 188, 190, 187, 150, 119, 109,  85,  79,  79,\n        78, 137, 203, 205, 206, 206, 207, 207, 206, 206, 204, 205, 204,\n       203, 202, 142, 151, 160, 172, 196, 188, 188, 190, 135,  96,  86,\n        77,  77,  79, 176, 205, 207, 207, 207, 207, 207, 207, 206, 206,\n       206, 204, 203, 202], dtype=int64)"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualizing the Data\n",
    "We need to represent 1D shape of 784 pixel, to a 2D shape of 28x28, same as with mnist data we need to reshape data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2880x2880 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAQAAAQhCAYAAAC6Bl1qAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAp0UlEQVR4nO3dz69d573X8WftvY99khPbcUOapG1+VEmle6uglFQQFPXHlaqqMEIgMaN0cGlR1Qmd8BcwZ8A/wOBWYliuuBIVl0EnqKhKQQHaug23uqGoTmLHTmzHxz4+ezFoLuTRbrYdGu/v43xeLylScrYjfbTW2muv8/avaZ7nBgAAAGRZVA8AAAAAdk8QAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAoFX1AADg7pqmaWqtvdha+5vv/vOHrbWHW2t/rbU2t9bebK39t9ban7XW/mSe58s1SwGAXZrmea7eAADcRdM07bfWrt/hD3+jtfbNeZ7/7V2cBAAMQBAAgI+49wSB/91a+8+ttZ+11s631l5vrZ1srf1Ba+0fttY+8+7/ctxa+7vzPP+H3a8FAHZFEACAj7hpmhattT+Y5/mnW37MsrX2r1pr3373Sz+f5/kPd7EPAKghCAAArbXWpmnaa639prX20Ltfenqe578onAQA3EX+lgEAoLXW2jzPR621X77nS49WbQEA7j5BAABorf3f31rw1Hu+dL5oCgCwA4IAAPBXfzXhv2j/71cF/Fe/XQAAPtpW1QMAgN2apunvtNb23/3P+1trz7TW/kFr7bl3v3axtfbHBdMAgB3yhwoCQJhpms631h75HS/dbK39aWvtn8/z/KvdrgIAds1vGQAA/srPW2t/3lp7vXoIAHD3+RUCABDq3T834FRr7dnW2j9qrX2rtbZsrf2P1trfm+f5fxbOAwDuMkEAAGittTZN09daa3/WfhsFftVa++vzPF+rXQUA3C1+ywAA0FprbZ7nH7TW/vW7//np1to/rlsDANxtggAA8F7//j3//kdVIwCAu08QAADe68p7/v3BqhEAwN0nCAAA7/XMe/79QtkKAOCuEwQAgNZaa9M0LVprf/yeL/2nqi0AwN0nCADAR9w0Tf9smqa/fZsfc6q19iettb/x7pfebK39m7u9DQCos6oeAADcdX/UWvuX0zT9srX2H1tr/721drG1dtxae7i19nxr7e+31j727o+/1Vr7J/M8X9z9VABgVwQBAMjxmXf/2eYvWmv/dJ7nP9/BHgCg0DTPc/UGAOAumqbpTGvti+23v1Lgb7XWHmutfby1dn/77d8q8L9aa/+ltfanrbV/N8/zzZqlAMAuCQIAAAAQyB8qCAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACbf1rB7/5zW8O9ScOnj17tnpC5/Tp09UTNhwcHFRP6Ozv71dP6Jw4caJ6Qmdvb696wgbHaLvVaqy/rXW5XFZP2DDaMRptz2jn7Pr169UTNoz2WTbaORttz4gWCz/ndS+Zpql6wgZ/8Pp26/W6esLwRruGXnzxxd/5RnO3BAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACDQatuLJ0+e3NWOO7JabZ27c8vlsnrChsVirMYz2jEa7fiMtqe18TZN01Q9oTPa8RntvtjaeJtGO2f7+/vVEzo/+MEPqids+PznP189ofPEE09UTxjaer2unjC80T7LuD3nbLvRPltHdK/cG51JAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAKttr24XC53teOOrFZb5+7caHtaG++cLRZjNadpmqondEa8hkY7Rq6h7Ubbw+2Ndp9+/fXXqydseOutt6ondNbrdfWEzmj3xdH2cO9xDd3eaPchbu9eua7vjZUAAADAh0oQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACDQatuLy+VyVzvuiD23N9qmaZqqJ3QWi7Ea2Gh7Whtvk2tou9H2jGi12vpRt3OHh4fVEzqXL1+unrBhtM+y0d5no90XgbtvtPvQer2unjC8eZ6rJ9yRsa4sAAAAYCcEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAECg1bYXl8vlrnbckcVirH4xTVP1hA2jHaPRrqG9vb3qCZ3Rjk9rra1WW28LOzfaMRptj/vQ7Z06dap6QufVV1+tntC5evVq9YQNZ86cqZ7QGe19Ntp7DH5fo73HuL3R7kPr9bp6woZ75boe60wCAAAAOyEIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAKttr24XC53teOO2HN7o21aLMZqTtM0VU/gAxrtGhrtPTbantZam+e5ekLn9OnT1RM6V65cqZ7QGfEaevDBB6snDM1nGb+v0T5bR7Rer6sndEY7Z47PR4cjBwAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAECg1bYX9/b2drXjjiyXy+oJncVivJ4yTVP1hM5oe0Yz4vEZ7X3mPrTdiPeh++67r3pC5+joqHpC59VXX62e0Nnf36+esGG0a2i099loe9brdfWEDaMdo9E+70c7PiMa7fOee8+I98bfxd0AAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAARaVQ/4IJbLZfWEzmh7Whtv02o11iU22vEZbU9r452zaZqqJ/ABnT59unpC5+23366e0Dl37lz1hM4TTzxRPWHD/v5+9YTOaPeh0e7TANWOj4+rJ9yz/AoBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAKttr642vryzi2Xy+oJndH2tDbepmmaqid0FouxGthoe1pzzm5ntPfYaMentdb29vaqJ3Tuv//+6gmdhx56qHpC5+zZs9UTNly+fLl6QmfEYzSS0e6LIxrts3We5+oJfEDHx8fVEzojPn+MZrT3/ftxJgEAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAItNr24t7e3q523JHFYqx+Mdqe1lqbpql6Qme5XFZP6Ix2fEbb09p41/Vox2i04zPae6y11larrR8tOzfaMfryl79cPaGzv79fPWHDD3/4w+oJnccff7x6QueFF16ontA5Pj6unjA898Xt1ut19YQN8zxXT+iMdg2NdnxGNNoz4/u5N1YCAAAAHypBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBote3FaZp2teOOjLZnuVxWT9iwWm09pTu3WIzVnOy5vdHeZ6Mdo9H2jHgfGs2JEyeqJ3Ru3bpVPaHzve99r3rChkceeaR6Quell16qntB5/vnnqyd0rl+/Xj1hw/nz56sndJ599tnqCZ3RPutH/Cyb57l6wtDW63X1hM5o3wO1Nt7n/fsZ68kWAAAA2AlBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAq60vrra+vHOLxVj9Ypqm6gnDWy6X1RM69tzeaJtG23Py5MnqCZ3HHnusesKG9XpdPaHz5ptvVk/oXLt2rXpC58qVK9UTNhweHlZP6Iz2PvvlL39ZPaFz//33V0/YcO7cueoJneeee656Ave40T5bR3s+m+e5esKG0Y7R+xnrO2wAAABgJwQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQKBV9YAPYrlcVk/oLBbj9ZQRN41ktGtotD2tjbfp4OCgekJntD1vvvlm9YQN165dq57QuXjxYvWEzk9+8pPqCZ1Tp05VT9jwxhtvVE/oPPPMM9UTOufPn6+eMLyXXnqpekLnK1/5SvWEzsc//vHqCcNbr9fVEzqjPZ/N81w9oXN8fFw9YcM0TdUT7ojvHgEAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAItKoe8EEsFmP1i2maqidsWK3GOqXL5bJ6Qme0a2i0Pa219rGPfax6QueBBx6ontDZ39+vntC5ceNG9YQNo73vX3/99eoJndH2vPnmm9UTNty8ebN6QufixYvVEzpvv/129YTOI488Uj1hwzvvvFM9ofP973+/ekLnW9/6VvWEzojP1KN9ls3zXD2hs16vqyd0Rjtf95LxvhsBAAAA7jpBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBote3F5XK5qx13ZJqm6gmd1Wrr4SuxWIzVeEY7Z6M5c+ZM9YQNTz/9dPWEzsWLF6sndH72s59VT+i88cYb1RM2XLlypXpCZ29vr3pC56mnnqqe0Llw4UL1hA3vvPNO9YTOr371q+oJnUuXLlVP6Dz//PPVEzacOnWqekLnF7/4RfWEzuHhYfWEzsHBQfWEDev1unrC0Eb7nmPE83WvfB801pkEAAAAdkIQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACDQqnrAvWyapuoJG0bbtFqNdYmNdnxOnjxZPWHDzZs3qyd0XnvtteoJnZdffrl6QudHP/pR9YQNP/3pT6sndJ5++unqCZ0vfvGL1RM6Dz74YPWEDaO972/cuFE9oXN4eFg9oXNwcFA9YcPR0VH1hM7e3l71hM59991XPaEz2vPZiEY7RvM8V0/oLBZ+nvv/lyMHAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQKDVthenadrVjjuyXC6rJ3QWCz3ldlxD956jo6PqCZ1f//rX1RM6586dq57Q+fnPf149YcPLL79cPaHzl3/5l9UTOl/96lerJ3RGe8+31trh4WH1hM6pU6eqJ3QODg6qJ3RWq62PkyVGe0Z76qmnqid0Rnsecg3d3vHxcfWEoa3X6+oJG0a7ht7PvbESAAAA+FAJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAq20vLhZj9YLR9kzTVD1hw3K5rJ7QGW3PaNbrdfWEDfM8V0/o7O/vV0/oPPTQQ9UTOmfPnq2esGG0e+Pjjz9ePaFzeHhYPaFz4cKF6gkb3nrrreoJnRMnTlRP6Hzyk5+sntC5fv169YQNV65cqZ7QefbZZ6sndE6ePFk9YXijfZax3Yjna7Rn6vcz1nfYAAAAwE4IAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAq20vTtO0qx18RM3zXD2hM9o1vV6vqydsGG3T3t5e9YTOfffdVz2h8/DDD1dP2PDEE09UT+hcunSpekLnxz/+cfWEzuXLl6snbHj88cerJ3SefPLJ6gmd/f396gmda9euVU/YcHR0VD2h84lPfKJ6Qme5XFZP6Iz27NHaeMdotD2jPeMfHx9XT9gw4nX9u/gVAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAg0Grbi4vFWL1gmqbqCcMb7Zwtl8vqCZ3RrqHVautbsMQ8z9UThnZwcFA9ofPoo49WT9jw5JNPVk/ovPLKK9UTOhcuXKie0PnsZz9bPWHDww8/XD2hc/r06eoJnYsXL1ZP6Fy6dKl6wobRrqHHHnusekJntOeh0Z5fR7Rer6snDG207zlaG+999n68+wAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAItNr24nK53NWOO7JYjNUvRjs+rY13jNju6OioesKGw8PD6gmd9XpdPaFz4sSJ6gmd0Y5Pa+PdGx944IHqCZ1HH320ekLnM5/5TPWEDQcHB9UTOteuXaue0Bnts2O089Vaa9/+9rerJ3RGO0ajPS+O+Fk22qbRztloRjtfrd075+zeWAkAAAB8qAQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQKDVthePj493teOOTNNUPaGzWIzXU0Y7RqPtWS6X1RM6R0dH1RP4gEa7Lx4eHlZP2LBabf1o2bnTp09XT+icOHGiekLn5s2b1RM2rNfr6gmdq1evVk/ovP3229UTOl//+terJ2x45plnqicMbcRn2NGMdh8a7Zl6nufqCZ0Rr+nRrqH3M96RAwAAAO46QQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQaLXtxeVyuasdd2SapuoJndH2tDbeOVssxmpOo+0Z0fXr16sndA4PD6sndEY7PiNe0w899FD1hM48z9UTOqPdp2/cuFE9YcO1a9eqJ3QuXrxYPaFz9uzZ6gmdF154oXrChr29veoJnfV6XT2h4754e6NtGu0aOj4+rp7QGfF56NatW9UT7sh4Rw4AAAC46wQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAKttr24WIzVC5bLZfWEzmjHp7XxNo12ztbrdfWEzv7+fvWEDcfHx9UTOrdu3aqeMLQzZ85UT9hwdHRUPaEzTVP1hM6VK1eqJ3RGe8+31to777xTPaFz8+bN6gmdb3zjG9UTOmfPnq2eMLzRns+4vdGeGV1D957Vauu32sNwZQEAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQaFU94IOYpql6wvBGO0br9bp6Qmdvb696QufEiRPVEzZcv369ekLn6OioekJntGv61q1b1RM2XLt2rXpC58aNG9UTOufPn6+e0Nnf36+esOHMmTPVEzrf+c53qid0XnzxxeoJndGePVprbbEY6+e8RvvsGM08z9UTNriGtlsul9UTOiNeQ/eKsa50AAAAYCcEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAACCQIAAAAQSBAAAACAQIIAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAECg1bYXl8vlrnbckxyf29vb26ue0Pn0pz9dPaHz61//unrCht/85jfVEzpXr16tntC5dOlS9YTOiNfQhQsXqid0bt68WT1haAcHB9UTNnz3u9+tntB57rnnqid0pmmqnjC80Y7RYuHn4O416/W6ekLHNbTdaOertdbmea6ecEdcWQAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEEgQAAAAgkCAAAAAAgQQBAAAACCQIAAAAQCBBAAAAAAIJAgAAABBIEAAAAIBAggAAAAAEWlUP+CAWi7H6xWh7RvSpT32qekJnvV5XT+g8/PDD1RM2vPLKK9UTOufOnaue0Ll8+XL1hM6FCxeqJ2y4fv169YShzfNcPaHzta99rXrChs997nPVEzrL5bJ6Qsfzx+1N01Q9YWij3Ye4vdGu6dGuodGOT2vjHaP34xMFAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAARaVQ/gw3VwcFA9ofPAAw9UT+hcvXq1ekJnsRivyX3pS1+qntB57bXXqid0XnnlleoJneVyWT1hw3q9rp4wtNHe91/4wheqJ2wY7boebQ/8vqZpqp7Qmee5esIG7/vtjo+PqyfwIRnrqQQAAADYCUEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEEgQAAAAgECCAAAAAAQSBAAAACCQIAAAAACBBAEAAAAIJAgAAABAIEEAAAAAAgkCAAAAEGia57l6AwAAALBjfoUAAAAABBIEAAAAIJAgAAAAAIEEAQAAAAgkCAAAAEAgQQAAAAAC/R/kWSjkrLUg6QAAAABJRU5ErkJggg==\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(40, 40))\n",
    "num_images = 10\n",
    "for i in range(num_images):\n",
    "    row = x_train[i]\n",
    "    label = y_train[i]\n",
    "\n",
    "    image = row.reshape(28,28)\n",
    "    plt.subplot(1,num_images+1,i+1) # Show more than one image\n",
    "    plt.title(label, fontdict = {'fontsize': 30})\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap = 'gray')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Normalize the Image Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 255)"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.min(), x_train.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Categorize the Labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 23)"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        1., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 1., 0., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n        0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_classes = 24\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_classes)\n",
    "y_train[0:23]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 24)                12312     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 676,888\n",
      "Trainable params: 676,888\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units = 512, activation = 'relu', input_shape=(784,)))\n",
    "model.add(Dense(units = 512, activation = 'relu'))\n",
    "model.add(Dense(units = 24, activation = 'softmax'))\n",
    "model.summary()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compiling the Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 1.9503 - accuracy: 0.3812 - val_loss: 1.3191 - val_accuracy: 0.5719\n",
      "Epoch 2/20\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 0.9746 - accuracy: 0.6700 - val_loss: 1.1568 - val_accuracy: 0.6319\n",
      "Epoch 3/20\n",
      "858/858 [==============================] - 7s 8ms/step - loss: 0.6001 - accuracy: 0.7972 - val_loss: 0.7953 - val_accuracy: 0.7680\n",
      "Epoch 4/20\n",
      "858/858 [==============================] - 7s 8ms/step - loss: 0.4113 - accuracy: 0.8659 - val_loss: 0.9289 - val_accuracy: 0.7945\n",
      "Epoch 5/20\n",
      "858/858 [==============================] - 7s 8ms/step - loss: 0.3047 - accuracy: 0.9074 - val_loss: 1.5262 - val_accuracy: 0.7185\n",
      "Epoch 6/20\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 0.2529 - accuracy: 0.9342 - val_loss: 2.8034 - val_accuracy: 0.5777\n",
      "Epoch 7/20\n",
      "858/858 [==============================] - 8s 9ms/step - loss: 0.2308 - accuracy: 0.9400 - val_loss: 0.7885 - val_accuracy: 0.8311\n",
      "Epoch 8/20\n",
      "243/858 [=======>......................] - ETA: 4s - loss: 0.2089 - accuracy: 0.9529"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [75]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m----> 3\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mx_valid\u001B[49m\u001B[43m,\u001B[49m\u001B[43my_valid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[0;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\keras\\engine\\training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[0;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateless_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2451\u001B[0m   (graph_function,\n\u001B[0;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1863\u001B[0m     args,\n\u001B[0;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1865\u001B[0m     executing_eagerly)\n\u001B[0;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TFpy\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "    x_train,y_train, epochs=20, verbose=1, validation_data=(x_valid,y_valid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Summary\n",
    "We can see that the training accuracy got to a high level, but validation accuracy was not as high.\n",
    "This is an example of the model learning to categorize the training data, but performing poorly against new data that has not been trained on. This is a common issue called `overfitting`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}